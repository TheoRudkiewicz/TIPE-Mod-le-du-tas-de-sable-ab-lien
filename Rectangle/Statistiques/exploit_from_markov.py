"""Permet de simuler le processus markovien et de récupérer des données issues de ce processus:
la configuration avec le moins de grains de sable (poids min),
le nombre d'apparition de chaque poids de configuration."""
# from Code.V2.general import *
from general import *
import numpy as np
import matplotlib.pyplot as plt
from pickle import Pickler, Unpickler


def standard_deviation(seq, mean):
    """Calcule l'écart type"""
    idx = np.int64(np.floor(mean))
    # under
    dx = mean - idx
    s = ((np.arange(idx, -1, -1) + dx) ** 2 * seq[:idx + 1]).sum()

    # upper
    dx = 1 - dx
    s += ((np.arange(seq.shape[0] - idx - 1) + dx) ** 2 * seq[idx + 1:]).sum()

    return np.sqrt(s / seq.sum())


def present_stat_markov(result, weight=True, conf_min=True, collapse=True, loosed=True):
    """Present stats generated by stats_for"""
    #  print(result)
    nb_line, nb_column, sample, weight_recurrent, min_array, collapse_weight, loosed_weight = result
    full_weight = nb_line * nb_column * 3

    if weight:
        # recurrent stats
        recurrent_mean = (weight_recurrent * np.arange(full_weight + 1)).sum() / weight_recurrent.sum()
        recurrent_max = np.where(weight_recurrent > 0)[0].max()
        recurrent_min = np.where(weight_recurrent > 0)[0].min()

        mu = recurrent_mean
        sigma = standard_deviation(weight_recurrent, recurrent_mean)
        gauss = ((1 / (np.sqrt(2 * np.pi) * sigma)) *
         np.exp(-0.5 * (1 / sigma * (arange(full_weight + 1) - mu))**2))

        #  recurrent graphics
        plt.hist(range(full_weight + 1), bins=full_weight, range=(0, full_weight), weights=weight_recurrent,
                 density=1, color='blue')
        plt.plot(range(full_weight + 1), gauss, '--', label=f"Normal({round(mu, 1)}, {round(sigma, 1)})", color='orange' )
        plt.axvline(recurrent_mean, color='red', label=f"Moyenne à {round(recurrent_mean, 1)}")
        plt.legend()
        plt.xlabel('Poids des configurations')
        plt.ylabel("Fréquence d'apparition")
        plt.title(f"Poids des configurations récurrentes pour une taille de {nb_line}x{nb_column}.\n" +
                  f"({sample} configurations observées)\n" +
                  f"Min: {recurrent_min}; Projected min: {round(2 * recurrent_mean - full_weight, 1)} (théorique: {(nb_line - 1) * nb_column + (nb_column - 1) * nb_line});\n" +
                  f"Max: {recurrent_max} (théorique: {full_weight})")
        plt.show()

    if conf_min:
        show(min_array, title=f"Configuration recurente minimale (poids: {min_array.sum()})")

    if collapse:
        # collapse stats
        collapse_mean = (collapse_weight * np.arange(6 * full_weight)).sum() / collapse_weight.sum()
        collapse_max = np.where(collapse_weight > 0)[0].max()
        collapse_min = np.where(collapse_weight > 0)[0].min()

        # collapse graphics
        plt.plot(range(full_weight * 6), collapse_weight, '*', label="Nombre d'avalanche")
        plt.axvline(collapse_mean, color='red', label=f"Moyenne à {round(collapse_mean, 1)}")
        plt.legend()
        plt.xlabel('Poids des avalanches')
        plt.ylabel("Fréquence d'apparition")
        plt.title(f"Poids des avalanches pour une taille de {nb_line}x{nb_column}.\n" +
                  f"({sample} avalanches observées)\n" +
                  f"Min: {collapse_min} ; Moy: {round(collapse_mean, 1)} ; Max: {collapse_max}\n" +
                  f"Min th: 1")
        plt.show()

    if loosed:
        # loosed stats
        loosed_mean = (loosed_weight * np.arange(full_weight + 1)).sum() / loosed_weight.sum()
        loosed_max = np.where(loosed_weight > 0)[0].max()
        loosed_min = np.where(loosed_weight > 0)[0].min()

        # collapse graphics
        plt.plot(range(full_weight + 1), loosed_weight, '*', label="Nombre d'avalanche")
        plt.axvline(loosed_mean, color='red', label=f"Moyenne à {round(loosed_mean, 1)}")
        plt.legend()
        plt.xlabel('Nombre de grains perdus')
        plt.ylabel("Fréquence d'apparition")
        plt.title(f"Nombre de grains perdus pour une taille de {nb_line}x{nb_column}.\n" +
                  f"({sample} avalanches observées)\n" +
                  f"Min: {loosed_min} ; Moy: {round(loosed_mean, 1)} ; Max: {loosed_max}\n" +
                  f"Min th: 0 ; Max conj: {2 * (nb_line + nb_column)}")
        plt.show()


def present_from_load(nb_line, nb_column, sample, weight=True, conf_min=True, collapse=True, loosed=True):
    """Present stats saved"""
    with open(f"Data\Markov\markov_{nb_line}_{nb_column}_{sample}", 'rb') as file:
        pic = Unpickler(file)
        present_stat_markov(pic.load(), weight, conf_min, collapse, loosed)


if __name__ == '__main__':
    present_from_load(100, 100, 10000000, True, True, True, True)
